{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55560abb-3487-42a5-816a-5f52ae1966bc",
   "metadata": {},
   "source": [
    "# Descriptive analysis of CNB minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb425b-e230-4877-91a7-7bc1ba477792",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c8e10c-648c-475e-9001-5e4d74094f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878a5d2-a6f3-422f-88a1-4d358027abaf",
   "metadata": {},
   "source": [
    "## Write function that retrieves information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6c7580-4507-4d2e-b6ea-c674d87f9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_texts(directory_path):\n",
    "    # Initialize counters\n",
    "    doc_count = 0\n",
    "    total_words = 0\n",
    "    total_sentences = 0\n",
    "    \n",
    "    # Define a regex pattern for sentence endings\n",
    "    sentence_pattern = re.compile(r'[.!?]')\n",
    "    \n",
    "    # Loop through all txt files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            doc_count += 1  # Count each document\n",
    "            with open(os.path.join(directory_path, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                \n",
    "                # Count words and sentences\n",
    "                words = text.split()\n",
    "                word_count = len(words)\n",
    "                sentences = sentence_pattern.split(text)\n",
    "                sentence_count = len([s for s in sentences if s.strip() != \"\"])\n",
    "                \n",
    "                # Accumulate totals\n",
    "                total_words += word_count\n",
    "                total_sentences += sentence_count\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_words_per_doc = total_words / doc_count if doc_count else 0\n",
    "    avg_sentences_per_doc = total_sentences / doc_count if doc_count else 0\n",
    "    avg_words_per_sentence = total_words / total_sentences if total_sentences else 0\n",
    "    \n",
    "    # Print or return the results\n",
    "    print(f\"Number of documents: {doc_count}\")\n",
    "    print(f\"Average words per document: {avg_words_per_doc:.2f}\")\n",
    "    print(f\"Average sentences per document: {avg_sentences_per_doc:.2f}\")\n",
    "    print(f\"Average words per sentence: {avg_words_per_sentence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed89b0-4679-4b94-bb4b-74772bb2ba35",
   "metadata": {},
   "source": [
    "## Use function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48e3ca6-eb24-49db-b2a9-e372f9f97e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 265\n",
      "Average words per document: 1007.37\n",
      "Average sentences per document: 47.34\n",
      "Average words per sentence: 21.28\n"
     ]
    }
   ],
   "source": [
    "# Call the function with the path to your directory\n",
    "directory_path = \"/Users/bernhardbrunner/Desktop/masters_thesis/data/cnb_minutes\"\n",
    "analyze_texts(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
